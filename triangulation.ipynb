{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create by Tianze (Steven) Shou during the RETTL project in Summer 2022 in Vincent's lab under the mentorship of Shamya Karumbaiah. \n",
    "\n",
    "This file is serves as a pipeline that takes in Pozyx position data, detect stops according to given parameters (duration and radius), and compare with the distilled observation log event data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python setup \n",
    "import pandas as pd\n",
    "import stop_detection as sd \n",
    "import numpy as np\n",
    "import copy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function definition \n",
    "def isWithinStop(row, stop): \n",
    "\n",
    "    \"\"\"\n",
    "    :param row: a pandas dataframe with only one row, has to have column named `time_stamp` \n",
    "    :param stop: a stop represented by a tuple, denoting the start and end timestamp of a stop\n",
    "    :return: returns a boolean of whether this row's timestamp is within the given stop \n",
    "    \"\"\"\n",
    "\n",
    "    assert(type(stop) == tuple and len(stop) == 2) \n",
    "\n",
    "    stopStart, stopEnd = stop \n",
    "    rowTimestamp = row.loc[\"time_stamp\"]\n",
    "\n",
    "    return stopStart <= rowTimestamp and rowTimestamp <= stopEnd\n",
    "\n",
    "\n",
    "\n",
    "def getStopEvent(posDF, stops): \n",
    "\n",
    "    \"\"\"\n",
    "    This function generates the events and centroids of classroom actor's stops\n",
    "    :param posDF: a pandas dataframe denoting the position data of an real-world object. Must have columns `chosen_X`, `chosen_Y`, and `time_stamp` \n",
    "    :param stops: an array of tuples denoting the start and end timestamps of stops. Usually values returned by sd.getStops()\n",
    "    :return: returns a tuple of three arrays. The first is an array of strings, denoting the stopping events; the second \n",
    "             is a string of tuple points, denoting stop centroid coordinates; the third is a list of stop indeces to be \n",
    "             put into posDF. \n",
    "    \"\"\"\n",
    "\n",
    "    # values to be returned \n",
    "    events = [] \n",
    "    centroids = []\n",
    "    stop_indeces = [] \n",
    "\n",
    "    i, j = 0, 0 # i is index for posDF; j is for indexing the list stops\n",
    "    while(j < len(stops) ): \n",
    "        currStop = stops[j] \n",
    "        currStopStartInd = i\n",
    "        inStop = False\n",
    "\n",
    "        while(i < len(posDF) and isWithinStop(posDF.loc[i], currStop)): \n",
    "            inStop = True # indicate to the following code that we do run into the current stop \n",
    "            i += 1\n",
    "            \n",
    "        if(inStop): # did run into a stop, currStopInd and i shoud not be the same\n",
    "            assert(currStopStartInd != i)\n",
    "\n",
    "            rows = posDF.loc[currStopStartInd:i-1] # rows that are within currStop \n",
    "            points = sd.cols2tuples(rows.chosen_X, rows.chosen_Y) \n",
    "            centroid = sd.getCentroid(points) # get the centroid of current stop \n",
    "            assert(type(centroid) == tuple and len(centroid) == 2) # ensures that centroid is a point represented by a tuple\n",
    "\n",
    "            stop_index = j \n",
    "\n",
    "            event = \"Stopping in location: \" + str(centroid) # format event in string\n",
    "            \n",
    "            # need to append multiple events since we are treating stop as a continuous event now\n",
    "            for k in range(i - currStopStartInd):\n",
    "                events.append(event) \n",
    "                centroids.append(centroid) \n",
    "                stop_indeces.append(stop_index)\n",
    "\n",
    "            j += 1 # we have found all rows corresponding to the current stop, go to next stop\n",
    "\n",
    "        else: # did not run into the current stop \n",
    "            assert(currStopStartInd == i)\n",
    "\n",
    "            # not stopping event, denote as moving \n",
    "            events.append(\"Moving\") \n",
    "            centroids.append(np.nan)\n",
    "            stop_indeces.append(np.nan)\n",
    "\n",
    "            # need to go to next row in position dataframe \n",
    "            i += 1\n",
    "    \n",
    "    # j reaches the end of stop list, but we still need to populate the events list to the same length as the original position dataframe \n",
    "    while(i < len(posDF)): \n",
    "        events.append(\"Moving\") \n",
    "        centroids.append(np.nan)\n",
    "        stop_indeces.append(np.nan)\n",
    "        i += 1\n",
    "\n",
    "    assert( len(events) == len(posDF) )\n",
    "    assert( len(centroids) == len(posDF) )\n",
    "    assert( len(stop_indeces) == len(posDF) )\n",
    "            \n",
    "    return events, centroids, stop_indeces\n",
    "\n",
    "\n",
    "def getClosestObjs(actorDF, objDF, rng): \n",
    "    \"\"\"\n",
    "    This function returns a list of tuples, where the list is of the same length as actorDF. Tuples contain the names of top objects closest to the centroid stopping points specified in actorDF. Length of tuples are specified by numOfObjs parameter\n",
    "    \n",
    "    :param actorDF: pandas dataframe documenting the position of an `actor` by continuous unix timestamp. Must contain column `centroid` \n",
    "    :param objDF: pandas dataframe documenting the coordinates of all classroom objects. Must have columns: `object`, `X`, and `Y` \n",
    "    :param rng: range parameter; of any classroom objects is with the range distance of the stop centroid, this object gets thrown to the set of objects\n",
    "    :return: returns a list of tuples. List is of the same length as actorDF. Tuples contain top objects closest to centroids of stops \n",
    "    \"\"\"\n",
    "    assert(type(rng) == int or type(rng) == float) \n",
    "    assert(rng > 0)\n",
    "\n",
    "    closestObjs = [] # value to be returned, going to contain dictionaries in {<objName1>:<distance1>, <objName2>:<distance2>} format \n",
    "    centroids = actorDF.centroid # centroid points for stops, represented by tuples of two ints \n",
    "    objPoints = sd.cols2tuples(objDF.X, objDF.Y) # X Y coordinates for classroom objects \n",
    "    objNames = objDF.object \n",
    "    assert(len(objNames) == len(objPoints)) # these two list/series should have one-to-one corresponding relation \n",
    "\n",
    "    i = 0 # indexing for centroids \n",
    "    while(i < len(centroids)): \n",
    "\n",
    "        centroid = centroids.iloc[i]\n",
    "        if( np.any(np.isnan(centroid)) ): # actor is not in a stop \n",
    "            closestObjs.append(np.nan)\n",
    "\n",
    "        elif(i - 1 >= 0 and centroids[i-1] == centroid): # if this current centroid is not the first one in the dataframe, and the previous centroid is the same as the current\n",
    "            objDistDict = copy.deepcopy(closestObjs[len(closestObjs)-1]) # copy the previous object-distance dictionary\n",
    "            closestObjs.append(objDistDict) # then append the copy\n",
    "\n",
    "        else: # this means that we need to go through the coordinates of all the classroom objects to find these within range and append them to closetObjs list \n",
    "            objDistDict = dict() # create an empty dictionary to hold the entries in the future \n",
    "            \n",
    "            j = 0\n",
    "            while(j < len(objNames)): \n",
    "                if( sd.getDist(centroid, objPoints[j]) < rng ): # if object j within range\n",
    "                    objDistDict[ objNames[j] ] = sd.getDist(centroid, objPoints[j]) # create a new entry as <object name>:<distance to centroid>\n",
    "                j += 1\n",
    "\n",
    "            closestObjs.append(objDistDict) \n",
    "\n",
    "        i += 1\n",
    "\n",
    "    assert(len(closestObjs) == len(actorDF)) # ensure that output length is correct \n",
    "    return(closestObjs)\n",
    "\n",
    "def isEmpty(obj): \n",
    "    return not bool(obj)\n",
    "\n",
    "\n",
    "def getObsInTimeframe(obsDF, timeframeStart, timeframeEnd): \n",
    "    obsTimestamps = obsDF[\"timestamp\"] \n",
    "    # timestamps of observation data are ensured to be monotonically sorted \n",
    "    timeframeStartInd = obsTimestamps.searchsorted(timeframeStart) \n",
    "    timeframeEndInd = obsTimestamps.searchsorted(timeframeEnd) \n",
    "    return obsDF.loc[timeframeStartInd:timeframeEndInd] \n",
    "\n",
    "def calcTriangulationScoreAndPercentages(posDF, obsDF, n_stops, timeframe=10): \n",
    "\n",
    "    \"\"\"\n",
    "    :param posDF: distilled pozyx position data with stopping event and possible subjects specified \n",
    "    :param obsDF: distilled observation log data. See observation_distilled_sprint1_shou.tsv for an example \n",
    "    :param reward: reward points given when true subject in observaiton log appears in the set of possible subjects \n",
    "    :param penalty: penalty points deducted when incorrent subjects appear in possible subject set \n",
    "    :param timeframe: specified how many seconds we look back in time to find the correct subject, unit is second. \n",
    "    :return: returns the triangulation validation score for a combination of parameters; higher score means better alignment between modalities \n",
    "    \"\"\"\n",
    "\n",
    "    # these two counts are for the calculation of recall \n",
    "    rightMatchCount = 0 \n",
    "    totalMatchCount = 0 \n",
    "    # these two counts are for the calculation of ~precision \n",
    "    rightGuessCount = 0\n",
    "    totalGuessCount = 0\n",
    "    # score of kind of the loss function here \n",
    "    score = 0\n",
    "    \n",
    "    i_rewards = i_penalties = 0\n",
    "    i_hits = i_false_alarms_inside = i_false_alarms_outside = i_misses = 0\n",
    "\n",
    "    # count for guesses that is accounted for during the first iteration, see \n",
    "    # Conrad <> Steven meeting notes for more information \n",
    "    seen_stop_indeces = set() \n",
    "\n",
    "    i = 0  # indexing for observation data \n",
    "    \n",
    "    # CB: G, S implementation looks good, seem minor comments below\n",
    "    while(i < len(obsDF)): \n",
    "        obsRow = obsDF.iloc[i] \n",
    "        obsEvent = obsRow[\"event\"] # event name specified in observation data \n",
    "\n",
    "        # events that we can to valid with position data \n",
    "        if(obsEvent == \"Talking to student: ON-task\" or\n",
    "           obsEvent == \"Talking to student: OFF-task\" or \n",
    "           obsEvent == \"Talking to small group: ON-task\" or \n",
    "           obsEvent == \"Talking to small group: OFF-task\"): \n",
    "\n",
    "            trueSubjects = obsRow[\"subject\"] # get the true subject(s) from observation data \n",
    "            assert(type(trueSubjects) == str and trueSubjects != \"\") # should now be a string but not empty, in format like \"12;13\"\n",
    "            trueSubjects = trueSubjects.split(\";\") # split by semicolon since seat numbers are demilited by semicolons in distilling process \n",
    "\n",
    "            # we look both back and forward in time in position dataframe to check for occurrence of the true subject \n",
    "            back = timeframe / 2\n",
    "            forward = timeframe - timeframe / 2\n",
    "            assert(back + forward == timeframe)\n",
    "            timeframeCenter = obsRow[\"timestamp\"] \n",
    "            timeframeStart = timeframeCenter - back \n",
    "            timeframeEnd = timeframeCenter + forward \n",
    "            # filter the position dataframe to get the rows within the timeframe and stopping \n",
    "            posInTimeframe = posDF[timeframeStart < posDF[\"time_stamp\"]][posDF[\"time_stamp\"] < timeframeEnd]\n",
    "            \n",
    "            \n",
    "            # CB: Bookmark 2.0:\n",
    "            # CB: Step 1: Add a column to posDF which is list(range(1, posDF.shape[0]+1))\n",
    "            # Step 2: Declare set outside of loop called seen_indices\n",
    "            # Step 3: seen_indices.add(posInTimeframe['index'])\n",
    "            # Step 4: After loop: Unseen guesses are posInTimeframe[~posInTimeframe['index'].isin(seen_indices)][\"possibleSubjects\"] \n",
    "            subjSets = posInTimeframe[\"possibleSubjects\"] \n",
    "            stop_indeces = posInTimeframe[\"stop_index\"] \n",
    "            seen_stop_indeces.union( set(stop_indeces) )\n",
    "\n",
    "            trueSubjects = [ \"seat\" + trueSubject for trueSubject in trueSubjects ]\n",
    "            S = set(trueSubjects) # S is the target set here \n",
    "            \n",
    "            \n",
    "            G = set() # populate Guess set G \n",
    "            for g in subjSets: # g is the individual guess set here, will be merged into big G \n",
    "                if isinstance(g, dict): \n",
    "                    G = G.union(g)\n",
    "                else: \n",
    "                    # this means that no guess is in the guess set g\n",
    "                    assert np.isnan(g) \n",
    "                    \n",
    "            hits = len( S.intersection(G) ) # number of hits = | S \\intersect G | \n",
    "            misses = len( S - G ) \n",
    "            false_alarms = len( G - S )\n",
    "\n",
    "            i_hits += hits \n",
    "            i_misses += misses \n",
    "            i_false_alarms_inside += false_alarms  # CB: rename i_false_alarms_inside\n",
    "            \n",
    "            for ind in range(len(trueSubjects)): # go thru trueSubjects list to see if they are included in possible subject sets \n",
    "\n",
    "                # trueSubject = \"seat\" + trueSubjects[ind] # convert to \"seat12\" format to align with position data \n",
    "                trueSubject = trueSubjects[ind]\n",
    "                bookMarkedSet = None # we bookmark the set we have seen to avoid counting repeating guesses/matches, only unique sets \n",
    "\n",
    "                for subjSet in subjSets: \n",
    "                    \n",
    "                    # CB: If I understand correctly, this counts the number of unique sets?\n",
    "                    # CB: If yes, note that bookmarked sets will be overwritten at each change \n",
    "                    #     in the sequence, which does not exactly count the number of unique sets,\n",
    "                    #     e.g., in sequence, AACAD -> {A,C,A,D} and not {A,C,D}\n",
    "                    # The more pythonic way of writing this would be a set of sets and len(),\n",
    "                    # where unfortunately the intermediate step must be a list, i.e.,\n",
    "                    #the_list = [set([1,2]),set([1,2]), set([1])]\n",
    "                    #the_list_len = len(set(frozenset(s) for s in the_list))\n",
    "                    # Challenge (only if you like): Re-write this for loop into two lines\n",
    "                    \n",
    "                    \n",
    "                #     if(type(subjSet) == dict): # this means that the teacher is detected to be stopping \n",
    "                #         if(isEmpty(subjSet)): \n",
    "                #             #score -= penalty # penalize if nothing is in the set \n",
    "                #             i_penalties += 1\n",
    "                #         elif(trueSubject in subjSet): \n",
    "                #             #score += reward # reward if true subject is in the set \n",
    "                #             i_rewards += 1\n",
    "                #             #score -= penalty * max(len(subjSet) - 1, 0) # penalize for every wrong guess in the set \n",
    "                #             i_penalties += max(len(subjSet) - 1, 0)\n",
    "                #         else: \n",
    "                #             #score -= penalty * len(subjSet) # penalize since all guesses are wrong \n",
    "                #             i_penalties += len(subjSet)\n",
    "                #     else: # teacher motion is detected, so subject set is NaN \n",
    "                #         assert(np.isnan(subjSet)) \n",
    "                #         #score -= penalty # penalize as if it is an empty set \n",
    "                #         i_penalties += 1\n",
    "\n",
    "                    # do counting for the percentages only to unique subject sets \n",
    "                    # we have seen this before, so skip\n",
    "                    if(subjSet == bookMarkedSet): \n",
    "                        pass \n",
    "                    # special case where subjSet is NaN, going to skip \n",
    "                    elif(not isinstance(subjSet, dict)): \n",
    "                        pass\n",
    "                    # we have not seen this, bookmark this set and do counting \n",
    "                    else: \n",
    "                        bookMarkedSet = subjSet\n",
    "                        totalGuessCount += len(subjSet) # the number of guesses is the number of guessed subjects \n",
    "                        totalMatchCount += 1 # one match attempt for each unique set \n",
    "                        if(trueSubject in subjSet): \n",
    "                            rightMatchCount += 1 # a correct match detected \n",
    "                            rightGuessCount += 1 # a correct guess detected \n",
    "                            # CB: rightMatchCount and rightGuessCount should always have the same value, no? why 2 values?\n",
    "                            # CB: Do we need this if we have hit, miss, false alarm? My hunch is no\n",
    "                            # CB: We only need the total counts\n",
    "                            # CB: Please also rename guesscount to n_guessed_subjects_total  and \n",
    "                            # CB: match count to n_guesses_total\n",
    "                            # CB: there are more intuitive names. Also, if time, check if the sets of sets operations\n",
    "                            # CB: change the output. As mentioned above I think the counting is not done correctly at the moment.\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    # we are going to increment false alarms with the quantity below to prevent \n",
    "    # encouraging the algo to generate numerous false stops just for ramdom \n",
    "    # guessing\n",
    "    # CB:\n",
    "    # See bookmark 2.0: Get step 4 unseen guesses (series of sets that are unseen guesses) sum([sum(set) for set in sets)]) | sum(df.sets.map(sum))\n",
    "    # i_false_alarms_outside = (<n students in non=bookmarked sets>)\n",
    "    # i_false_alarms_total = i_false_alarms_inside + i_false_alarms_outside\n",
    "\n",
    "    for i in posDF.index: \n",
    "        event = posDF.loc[i, \"event\"]\n",
    "        stop_index = posDF.loc[i, \"stop_index\"]\n",
    "        # only check stops we did not check before hand \n",
    "        if (\"Stopping\" in event) and (stop_index not in seen_stop_indeces): \n",
    "            i_false_alarms_outside += len(posDF.loc[i, \"possibleSubjects\"])\n",
    "            seen_stop_indeces.add(stop_index) # mark this stop as checked \n",
    "\n",
    "    try:\n",
    "        f1 = rightMatchCount / totalMatchCount\n",
    "    except ZeroDivisionError:\n",
    "        f1 = np.nan \n",
    "    try:\n",
    "        f2 = rightGuessCount / totalGuessCount\n",
    "    except ZeroDivisionError:\n",
    "        f2 = np.nan\n",
    "    return f1, f2, i_hits, i_misses, i_false_alarms_inside, i_false_alarms_outside\n",
    "\n",
    "\n",
    "def getPercentages(posStops, obsStops, timeframe, epsilon=0.01): \n",
    "\n",
    "    \"\"\"\n",
    "    :param posStops: stops datamined from position data, formatted as [(start_stop_1, end_stop_1), (start_stop_2, end_stop_2), ... ] \n",
    "    :param obsStops: stops datamined from observation data, formatted as [start_stop_1, start_stop_2, ... ] \n",
    "    :param timeframe: timeframe parameter specified in triangulation model \n",
    "    :return: returns three percentages, in-both%, in-position-only%, and in-observation-only%\n",
    "    \"\"\"\n",
    "\n",
    "    assert(type(posStops) == list and type(obsStops) == list) \n",
    "    posStopsCount = len(posStops) \n",
    "    obsStopsCount = len(obsStops) \n",
    "    inPosCount = 0 # number of stops only in position data, not in observation data \n",
    "    inObsCount = 0 # number of stops only in observation data, not in position data \n",
    "\n",
    "    # loop thru position stops to get these only in position not in observation \n",
    "    # use the fact that obsStop is a strictly increasing list of ints \n",
    "    for posStopStart, posStopEnd in posStops: \n",
    "\n",
    "        back = timeframe / 2\n",
    "        forward = timeframe - back \n",
    "        TFstart = posStopStart - back # timeframe start\n",
    "        TFend = posStopEnd + forward  # timeframe end \n",
    "\n",
    "        for obsStop in obsStops: \n",
    "\n",
    "            if(obsStop < TFstart): \n",
    "                # observation stop is before the timeframe setup by position stop, continue to the next observation stop\n",
    "                continue \n",
    "            elif(TFstart <= obsStop and obsStop <= TFend): \n",
    "                # this position stop is corresponding to this observation stop, so break \n",
    "                break\n",
    "            else: \n",
    "                # when gets here, it means that this position stop is not corresponding to any observation stops\n",
    "                assert(TFend < obsStop)\n",
    "                inPosCount += 1\n",
    "                break \n",
    "\n",
    "    # loop thru observation stops to get these only in observation not in position \n",
    "    # use the fact that posStops is a strictly increasing list of int tuples \n",
    "    for obsStop in obsStops: \n",
    "        for posStopStart, posStopEnd in posStops: \n",
    "\n",
    "            back = timeframe / 2\n",
    "            forward = timeframe - back \n",
    "            TFstart = posStopStart - back # timeframe start\n",
    "            TFend = posStopEnd + forward  # timeframe end \n",
    "\n",
    "            if(TFend < obsStop): \n",
    "                # observation stop is before the timeframe setup by position stop, continue to the next observation stop\n",
    "                continue \n",
    "            elif(TFstart <= obsStop and obsStop <= TFend): \n",
    "                # this position stop is corresponding to this observation stop, so break \n",
    "                break\n",
    "            else: \n",
    "                # when gets here, it means that this position stop is not corresponding to any observation stops\n",
    "                assert(obsStop < TFstart)\n",
    "                inObsCount += 1\n",
    "                break \n",
    "\n",
    "    # now in-position-only and in-observation-only counts have been calculated \n",
    "    # we need to get in-both count \n",
    "    inBothCount = int((obsStopsCount + posStopsCount - inObsCount - inPosCount) / 2) \n",
    "    assert(inBothCount > 0) # safety check \n",
    "    totalCount = inBothCount + inPosCount + inObsCount\n",
    "\n",
    "    # return the percentages \n",
    "    return inBothCount / totalCount, inPosCount / totalCount, inObsCount / totalCount \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_param_sweep(verbose=False, outputFileName = \"\", resolution={\"low\", \"medium\", \"high\", \"fine_grained\"}):\n",
    "    \"\"\"\n",
    "    verbose: print progress, yes/no\n",
    "    export: Write results to csv, yes/no \n",
    "    resolution: takes value from {\"low\", \"medium\", \"high\"}. Use \"low\" to test run code functionality. \n",
    "        Use \"medium\" to have fast, preliminary results. Use \"high\" to explore the search space more extensively. \n",
    "    \"\"\"\n",
    "    \n",
    "    # PLEASE LOOK FOR TODO'S AS THEY ARE NECESSARY CHANGES TO SETUP THIS CODE CHUNK \n",
    "\n",
    "    # read teacher position data\n",
    "    teacherPos = pd.read_csv(\"output_files/teacher_position_sprint1_shou.csv\", index_col=False) \n",
    "    objPos = pd.read_csv(\"raw data/seating_chart_x_y_seat_only_sprint1_shou.csv\", index_col=False) \n",
    "    obsLog = pd.read_csv(\"output_files/observation_events.tsv\", sep=\"\\t\", index_col=False) \n",
    "\n",
    "    # TODO: dataframe to hold the result of the sweep\n",
    "    sweepDF = pd.DataFrame() \n",
    "    #sweepDF = pd.read_csv(\"parameter_sweep_master_sprint1_shou.csv\", index_col=False) \n",
    "\n",
    "    duration_grid = None\n",
    "    radius_grid = None \n",
    "    range_grid = None\n",
    "    timeframe_grid = None \n",
    "    \n",
    "    if resolution == \"low\":\n",
    "        duration_grid = np.arange(3, 30, step=1500)\n",
    "        radius_grid = np.arange(200, 2000, step=100000)\n",
    "        range_grid = np.arange(100, 1500, step=50000)\n",
    "        timeframe_grid = np.arange(5, 19, step=100000)\n",
    "    elif resolution == \"high\":\n",
    "        duration_grid = np.arange(3, 30, step=4)\n",
    "        radius_grid = np.arange(200, 2000, step=200)\n",
    "        range_grid = np.arange(100, 1500, step=200)\n",
    "        timeframe_grid = np.arange(5, 19, step=4)\n",
    "    elif resolution == \"medium\": \n",
    "        duration_grid = np.arange(3, 31, step=9)\n",
    "        radius_grid = np.arange(200, 2000, step=600)\n",
    "        range_grid = np.arange(100, 1500, step=600)\n",
    "        timeframe_grid = np.arange(5, 20, step=9) \n",
    "    elif resolution == \"fine_grained\": \n",
    "        duration_grid = np.arange(3, 31, step=3)\n",
    "        radius_grid = np.arange(200, 2000, step=200)\n",
    "        range_grid = np.arange(100, 2000, step=200)\n",
    "        timeframe_grid = [10] # set timeframe to be 10 seconds, as discussed \n",
    "    else: \n",
    "        raise Exception(f\"Unknown resolution level {resolution}\")\n",
    "\n",
    "    \n",
    "    for duration in tqdm(duration_grid): \n",
    "        for radius in radius_grid: \n",
    "            for timeframe in timeframe_grid:\n",
    "\n",
    "                # call stop detection utility, get starting and end timestamp for each stop with corresponding parameters (duration, radius)\n",
    "                teacherStops = sd.getStops(teacherPos.chosen_X, teacherPos.chosen_Y, \n",
    "                                           teacherPos.time_stamp, teacherPos.periodID, \n",
    "                                           teacherPos.dayID, duration, radius) \n",
    "                obsStops = sd.getStopsFromObs(obsLog) \n",
    "\n",
    "                inBoth, inPos, inObs = getPercentages(teacherStops, obsStops, timeframe) \n",
    "\n",
    "                events, centroids, stop_indeces = getStopEvent(teacherPos, teacherStops) \n",
    "                teacherPos[\"event\"] = events # populate event column for teacher positon dataframe \n",
    "                teacherPos[\"centroid\"] = centroids \n",
    "                teacherPos[\"stop_index\"] = stop_indeces \n",
    "\n",
    "                for rng in range_grid: \n",
    "                    rng = int(rng)\n",
    "\n",
    "                    # check if the current set of parameters have been calculated \n",
    "                    if sweepDF.shape[0] > 0:\n",
    "                        filteredDF = sweepDF[ sweepDF[\"duration\"] == duration ]\n",
    "                        filteredDF = filteredDF[ filteredDF[\"radius\"] == radius ]\n",
    "                        filteredDF = filteredDF[ filteredDF[\"range\"] == rng ]\n",
    "                        filteredDF = filteredDF[ filteredDF[\"timeframe\"] == timeframe ] \n",
    "                        # if yes, skip this set and go to the next \n",
    "                        if( len(filteredDF) >= 1 ): \n",
    "                            if verbose:\n",
    "                                print(\"Parameter set\", duration, radius, rng, \"skipped\")\n",
    "                                print(\"###########################################\")\n",
    "                            continue \n",
    "\n",
    "                    # get the objects and their correpsonding distances to centroid within rng (range) \n",
    "                    subjects = getClosestObjs(teacherPos, objPos, rng)\n",
    "                    teacherPos[\"possibleSubjects\"] = subjects \n",
    "\n",
    "                    calc = calcTriangulationScoreAndPercentages\n",
    "                    rightMatchPercentage, rightGuessPercentage, \\\n",
    "                    n_hits, n_misses, n_false_alarms_inside, \\\n",
    "                    n_false_alarms_outside = calc(teacherPos, \n",
    "                                                  obsLog, \n",
    "                                                  len(teacherPos),\n",
    "                                                  timeframe=timeframe) \n",
    "\n",
    "                    # update sweep dataframe with each parameter set we test for \n",
    "                    newRow = {\"duration\": [duration], \n",
    "                              \"radius\": [radius], \n",
    "                              \"range\": [rng], \n",
    "                              \"perc_of_stops_in_both\": inBoth, \n",
    "                              \"perc_of_stops_in_pos\": inPos, \n",
    "                              \"perc_of_stops_in_obs\": inObs, \n",
    "                              \"right_match_percentage\": [rightMatchPercentage], \n",
    "                              \"right_guess_percentage\": [rightGuessPercentage],\n",
    "                              \"timeframe\": [timeframe],\n",
    "                              'n_hits': [n_hits],\n",
    "                              'n_misses': [n_misses], \n",
    "                              'n_false_alarms_inside': [n_false_alarms_inside], \n",
    "                              'n_false_alarms_outside': [n_false_alarms_outside]\n",
    "                             } \n",
    "                    newDF = pd.DataFrame(newRow)\n",
    "                    sweepDF = pd.concat([sweepDF, newDF], ignore_index=True)\n",
    "\n",
    "                    if verbose: \n",
    "                        print(f\"Hyperparameter timeframe is: {timeframe}\") \n",
    "                        print(\"Parameter set (duration, radius, range) is:\", duration, radius, rng) \n",
    "                        print(f\"n_hits is {n_hits}\")\n",
    "                        print(f\"n_misses is {n_misses}\")\n",
    "                        print(f\"n_false_alarms_inside is {n_false_alarms_inside}\")\n",
    "                        print(f\"n_false_alarms_outside is {n_false_alarms_outside}\")\n",
    "                        print(\"Three percentages are (in both, in position only, in observation only):\", inBoth, inPos, inObs) \n",
    "                        print(\"Right match percentage is\", rightMatchPercentage) \n",
    "                        print(\"Right guess percentage is\", rightGuessPercentage) \n",
    "                        print(\"###########################################\")\n",
    "\n",
    "    export = ( outputFileName != \"\" ) \n",
    "    if export:\n",
    "        try: \n",
    "            sweepDF.to_csv(outputFileName, index=False)\n",
    "            if verbose:\n",
    "                print(\"Changes to the data file has been saved to\", outputFileName)\n",
    "                print(\"###########################################\")\n",
    "        except Exception as e:\n",
    "            print(\"WARNING: Cannot export data file, just returning the dataframe object ...\")\n",
    "            print(\"The error raised is: \", e)\n",
    "            \n",
    "    return sweepDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Explore search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_avg_score(df_score):\n",
    "    return np.mean((df_score['right_match_percentage'] + df_score['right_guess_percentage'])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/29/l7nrj2kj79s5n10vdwh2ywnc0000gn/T/ipykernel_64865/1701139296.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mdf_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_param_sweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputFileName\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"output_files/parameter_sweep_full_v1.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fine_grained\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/29/l7nrj2kj79s5n10vdwh2ywnc0000gn/T/ipykernel_64865/2336704000.py\u001b[0m in \u001b[0;36mrun_param_sweep\u001b[0;34m(verbose, outputFileName, resolution)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# read teacher position data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mteacherPos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output_files/teacher_position_sprint1_shou.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mobjPos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"raw data/seating_chart_x_y_seat_only_sprint1_shou.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mobsLog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output_files/observation_events.tsv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df_ref = run_param_sweep(verbose=False, outputFileName=\"output_files/parameter_sweep_full_v1.csv\", resolution=\"fine_grained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    df_ref = pd.read_csv('parameter-search-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What hyperparams are most associated with accuracy?\n",
    "if __name__ == \"__main__\":\n",
    "    df_ref['match_guess_avg'] = (df_ref['right_match_percentage'] + df_ref['right_guess_percentage'])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for y in ['right_match_percentage', 'right_guess_percentage', 'n_rewards', 'n_penalties']:\n",
    "        print(f'\\nCorrelating with outcome {y}')\n",
    "        for x in ['duration', 'radius', 'range', 'timeframe']:\n",
    "            xx = df_ref[x]\n",
    "            yy = df_ref[y]\n",
    "            xxm = np.ma.masked_invalid(xx)\n",
    "            yym = np.ma.masked_invalid(yy)\n",
    "            msk = (~xxm.mask & ~yym.mask)\n",
    "            print(f'r({x}, {y}) = {round(np.corrcoef(xx[msk], yy[msk])[0][1], 3)}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Fine-tune reward and penality with regards to size of timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional code from Steven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    # read teacher position data\n",
    "    teacherPos = pd.read_csv(\"teacher_position_sprint1_shou.csv\", index_col=False) \n",
    "    objPos = pd.read_csv(\"seating_chart_x_y_sprint1_shou.csv\", index_col=False) \n",
    "    obsLog = pd.read_csv(\"observation_distilled_sprint1_shou.tsv\", sep=\"\\t\", index_col=False) \n",
    "\n",
    "    # parameter setting \n",
    "    duration = 15\n",
    "    radius = 500\n",
    "    rng = 2000\n",
    "\n",
    "    # call stop detection utility, get starting and end timestamp for each stop \n",
    "    teacherStops = sd.getStops(teacherPos.chosen_X, teacherPos.chosen_Y, \n",
    "                            teacherPos.time_stamp, teacherPos.periodID, \n",
    "                            teacherPos.dayID, duration, radius) \n",
    "\n",
    "    events, centroids = getStopEvent(teacherPos, teacherStops) \n",
    "    teacherPos[\"event\"] = events # populate event column for teacher positon dataframe \n",
    "    teacherPos[\"centroid\"] = centroids \n",
    "\n",
    "    # get the objects and their correpsonding distances to centroid within rng (range) \n",
    "    subjects = getClosestObjs(teacherPos, objPos, rng)\n",
    "    teacherPos[\"possibleSubjects\"] = subjects \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "39d0902a1036906d99cac176d872c3f89dde3e51b38a3c18e9adb4af2bfcf134"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
